---
title: "Clasificación doctech"
author: "Luis Daniel Chavarría"
date: "20/11/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Clasificación de causas de rechazo de documentos técnicos

El objetivo de este trabajo es clasificar los planos de acuerdo a sus motivos de rechazo en 3 categorías: 

- Forma: El plano tiene errores en la distribución, cajetines, faltas en símbolos, entre otros.
- Rigor técnico: El plano tiene errores técnicos graves o faltas de especificaciones, por lo que debe ser revisado a profundidad.
- Procedimiento: El plano fue enviado a circuito de firmas de manera incorrecta, por ejemplo, cuando no se citan los pool de firmantes necesarios o cuando se cita a un validador que no está capacitado para hacerlo.

## El método

Julia Silge en su [viñeta](https://www.r-bloggers.com/text-classification-with-tidy-data-principles/) propone el modelo de regresión  con regularización LASSO para la clasificación basada en palabras y obtienen resultados muy interesantes realizando clasificaciones adecuadas para dos libros: La guerra de los mundos vs Orgullo y prejuicio.

# Librerías

```{r}
library(tidyverse)
library(glmnet)
library(tidytext)
library(data.table)
library(rsample)
library(yardstick)
library(broom)

raw_verbatim <- fread("consolidado_ph2.csv") %>% as_tibble()
planos <- fread("planos_pt2.csv", encoding = "UTF-8") %>% as_tibble() %>% 
  mutate(PIE_numero = str_trim(PIE_numero))
```

# Data cleaning

```{r}
clean_verbatim <- raw_verbatim %>% 
  filter(Maturity == "Refused") %>% 
  inner_join(planos, by = c("Name/Id" = "DOCTECH_numero")) %>% 
  mutate(Comentarios = str_trim(Comentarios),
         causa_rechazo = NA) %>% 
  rownames_to_column()
```

# Stratified Sampling

¿Cuáles perímetros están menos representados? 

```{r}
clean_verbatim %>% 
  count(ELTDEC_numero, sort = T) %>% 
  mutate(ELTDEC_numero = as_factor(ELTDEC_numero)) %>% 
  ggplot(aes(x = ELTDEC_numero, y = n)) +
  geom_col() +
  scale_y_log10()
```

Los perímetros B4, B1, 55, 56 Y 94 cuentan con menos de 10 observaciones. Se excluirán para el muestreo aleatorio y se agregarán posteriormente con su total de observaciones.

```{r}
set.seed(1)
rare_eltdec <- clean_verbatim %>% 
  filter(ELTDEC_numero == "B4" | ELTDEC_numero == "B1" | ELTDEC_numero == "55" | ELTDEC_numero == "56" | ELTDEC_numero == "94")


muestra <- clean_verbatim %>% 
  anti_join(rare_eltdec, by = "Name/Id") %>%
  filter(Comentarios != "") %>%
  group_by(ELTDEC_numero) %>% 
  sample_n(size = 15) %>%
  ungroup() %>% 
  bind_rows(rare_eltdec)

write_excel_csv2(muestra, "global_train_set.csv")
```

```{r}
global_train_set <- fread("global_train_set.csv", encoding = "UTF-8") %>% as_tibble() %>% mutate(rowname = as.character(rowname))
```


# Modeling

```{r}
tidy_words <- global_train_set %>% 
  select(rowname, `Name/Id`, Comentarios, ELTDEC_numero, 
         ELTDEC_designation, FCT_numero, FCT_designation, 
         ESO_num_PG, ESO_designation_PG, PIE_numero, 
         PIE_designation, PIEIND_Dernier_indice, PIEIND_typologie, causa_rechazo) %>% 
  mutate(Comentarios = str_replace_all(Comentarios, "\n", " ")) %>% 
  unnest_tokens(word, Comentarios) %>%
  group_by(word) %>%
  filter(n() >= 5) %>%  
  ungroup()
```


```{r}
words_frequency <- tidy_words %>%
  filter(causa_rechazo != "") %>% 
  count(causa_rechazo, word, sort = T) %>% 
  anti_join(get_stopwords(language = "en"), by = "word") %>% 
  anti_join(get_stopwords(language = "fr"), by = "word") %>% 
  anti_join(get_stopwords(language = "pt"), by = "word") %>% 
  anti_join(get_stopwords(language = "es"), by = "word") %>%
  filter(word != "ok")

words_frequency %>%
  group_by(causa_rechazo) %>%
  top_n(40) %>%
  ungroup() %>%
  ggplot(aes(reorder_within(word, n, causa_rechazo), n, fill = causa_rechazo)) +
  geom_col(alpha = 0.8, show.legend = FALSE) +
  scale_x_reordered() +
  coord_flip() +
  facet_wrap(~causa_rechazo, scales = "free") + 
  scale_y_continuous(expand = c(0, 0)) +
  labs(x = NULL, y = "Palabras", title = "Palabras más comunes después de remover stop words")

# ggsave("frequency.png", units = "mm", width = 215, height = 279)
```

# Testing and training data split

```{r}
set.seed(1995)
word_split <- global_train_set %>%
  filter(causa_rechazo != "") %>% 
  select(rowname, `Name/Id`, Comentarios, ELTDEC_numero, 
         ELTDEC_designation, FCT_numero, FCT_designation, 
         ESO_num_PG, ESO_designation_PG, PIE_numero, 
         PIE_designation, PIEIND_Dernier_indice, PIEIND_typologie, causa_rechazo) %>%
  initial_split()

train_data <- training(word_split)
test_data <- testing(word_split)
```

# Transforming data to a sparse matrix to use on the machine learning algorithm

```{r}
sparse_words <- tidy_words %>%
  count(rowname, word) %>%
  anti_join(get_stopwords(language = "en"), by = "word") %>% 
  anti_join(get_stopwords(language = "fr"), by = "word") %>% 
  anti_join(get_stopwords(language = "pt"), by = "word") %>% 
  anti_join(get_stopwords(language = "es"), by = "word") %>% 
  inner_join(train_data, by = "rowname") %>%
  cast_sparse(rowname, word, n)

dim(sparse_words)
```

One reason this overall approach is flexible and wonderful is that you could at this point cbind() other columns, such as non-text numeric data, onto this sparse matrix. Then you can use this combination of text and non-text data as your predictors in the machine learning algorithm, and the regularized regression algorithm we are going to use will find which are important for your problem space. I’ve experienced great results with my real world prediction problems using this approach.- Julia Silge

```{r}
word_rownames <- as.integer(rownames(sparse_words))

words_joined <- tibble(rowname = as.character(word_rownames)) %>%
  left_join(global_train_set %>%
    select(rowname, causa_rechazo))
```

# Training the model and using the processor

This part has some real creativity, because all the examples have only binomial classification. Let's see.

```{r}
response <- words_joined$causa_rechazo %>% as_factor()

words_model <- cv.glmnet(sparse_words, response,
  family = "multinomial",
  keep = TRUE
)

plot(words_model$glmnet.fit)
plot(words_model)
```

# Digging into the coefficients

```{r}

coefs <- words_model$glmnet.fit %>%
  tidy() %>%
  filter(lambda == words_model$lambda.1se)



coefs %>%
  ggplot(aes(fct_reorder(term, estimate), estimate, fill = class)) +
  geom_col(alpha = 0.8, position = position_dodge2()) +
  coord_flip() +
  facet_wrap(~class, scales = "free") +
  labs(x = "Coeficientes",
       y = "Estimaciones",
       title = "Palabras que contribuyen a que un comentario sea de una categoría",
       subtitle = "Elastic-Net Model")


# ggsave("coefs.png", units = "mm", width = 215, height = 250)
```

# Test set trial

No es correcto utilizar la función predict para este tipo de casos en predicción con base en palabras, ya que cada fila contiene muchas palabras y se estaría realizando una predicción por palabra, lo que es incorrecto. Se deben concentrar los esfuerzos en los coeficientes.

# ```{r}
# predict(words_model, newx = sparse_words_test, s = "lambda.min", type = "class")
# ```

Do I need an intercept? I don't have it anyway.

```{r}
# intercept <- coefs %>%
#   filter(term == "(Intercept)") %>%
#   pull(estimate)

classifications <- tidy_words %>%
  inner_join(test_data) %>%
  inner_join(coefs, by = c("word" = "term")) %>%
  group_by(rowname, `Name/Id`, class) %>%
  summarize(score = sum(estimate)) %>%
  mutate(probability = plogis(score)) %>% 
  summarize(prob = max(probability), 
            response = class[which(probability == max(probability))]) %>% 
  ungroup()

```

This would be the highest likelihood classification obtained for the model, given that a single response is needed.

# From Julia's text

Joining the classifications with the training set

```{r}
train_validation <- classifications %>%
  left_join(global_train_set %>%
    select(causa_rechazo, rowname), by = "rowname") %>%
  mutate(causa_rechazo = fct_relevel((as_factor(causa_rechazo)), "técnico", "forma", "procedimiento"),
         response = fct_relevel((as_factor(response)), "técnico", "forma", "procedimiento"))
```

# Matriz de confusión y validación



```{r}
confusion <- train_validation %>% 
  conf_mat(causa_rechazo, response)

accuracy <- (confusion[[1]][1] + confusion[[1]][5] + confusion[[1]][9]) / sum(unlist(confusion))
confusion
accuracy
```

60% Accuracy (TP + TN) / Total is quite a good measure for a first try. Let's now use the model on the real data. `global_train_set.csv` is a stratified sample from `clean_verbatim`. Will model performance improve if it is trained with the entire train data? Likely yes, so let's do it!

Results seem a little bit overfit by looking at the coefficients, but that can be handled. A big question is wheter a comment may not have any words of the ones specified in the coefficients.

# Evaluación y aplicación del modelo en los datos generales

Missing the training on the complete data. Let's overfit the model! Creating the objects needed to run the model

```{r}
final_train <- global_train_set %>%
  filter(causa_rechazo != "") %>% 
  select(rowname, `Name/Id`, Comentarios, ELTDEC_numero, 
         ELTDEC_designation, FCT_numero, FCT_designation, 
         ESO_num_PG, ESO_designation_PG, PIE_numero, 
         PIE_designation, PIEIND_Dernier_indice, PIEIND_typologie, causa_rechazo)

final_sparse_words <- tidy_words %>%
  count(rowname, word) %>%
  anti_join(get_stopwords(language = "en"), by = "word") %>% 
  anti_join(get_stopwords(language = "fr"), by = "word") %>% 
  anti_join(get_stopwords(language = "pt"), by = "word") %>% 
  anti_join(get_stopwords(language = "es"), by = "word") %>% 
  cast_sparse(rowname, word, n)

dim(final_sparse_words)

final_word_rownames <- as.integer(rownames(final_sparse_words))

final_words_joined <- tibble(rowname = as.character(final_word_rownames)) %>%
  left_join(global_train_set %>%
    select(rowname, causa_rechazo))

final_response <- final_words_joined$causa_rechazo %>% as_factor()
```


```{r}
final_words_model <- cv.glmnet(final_sparse_words, final_response,
  family = "multinomial",
  keep = TRUE
)

plot(final_words_model$glmnet.fit)
plot(final_words_model)

final_coefs <- final_words_model$glmnet.fit %>%
  tidy() %>%
  filter(lambda == final_words_model$lambda.1se)



final_coefs %>%
  ggplot(aes(fct_reorder(term, estimate), estimate, fill = class)) +
  geom_col(alpha = 0.8, position = position_dodge2()) +
  coord_flip() +
  facet_wrap(~class, scales = "free") +
  labs(x = "Coeficientes",
       y = "Estimaciones",
       title = "Palabras que contribuyen a que un comentario sea de una categoría",
       subtitle = "Elastic-Net Model - Overfit version")


# ggsave("final_coefs.png", units = "mm", width = 215, height = 250)

final_classifications <- tidy_words %>%
  inner_join(global_train_set) %>%
  inner_join(final_coefs, by = c("word" = "term")) %>%
  group_by(rowname, `Name/Id`, class) %>%
  summarize(score = sum(estimate)) %>%
  mutate(probability = plogis(score)) %>% 
  summarize(prob = max(probability), 
            response = class[which(probability == max(probability))]) %>% 
  ungroup()

final_validation <- final_classifications %>%
  left_join(global_train_set %>%
    select(causa_rechazo, rowname), by = "rowname") %>%
  mutate(causa_rechazo = fct_relevel((as_factor(causa_rechazo)), "técnico", "forma", "procedimiento"),
         response = fct_relevel((as_factor(response)), "técnico", "forma", "procedimiento"))
```

# Matriz de confusión y validación del modelo sobreajustado

```{r}
final_confusion <- final_validation %>% 
  conf_mat(causa_rechazo, response)

final_accuracy <- (final_confusion[[1]][1] + final_confusion[[1]][5] + final_confusion[[1]][9]) / sum(unlist(final_confusion))
final_confusion
final_accuracy
```

The overfit model performed with a positive detection rate of 74.61% on the first try, therefore, the overfit model will be assumed as a better option to classify the out-of-sample observations because of a overall higher train data.

```{r}
tidy_final <- clean_verbatim %>% 
  select(rowname, `Name/Id`, Comentarios, ELTDEC_numero, 
         ELTDEC_designation, FCT_numero, FCT_designation, 
         ESO_num_PG, ESO_designation_PG, PIE_numero, 
         PIE_designation, PIEIND_Dernier_indice, PIEIND_typologie, causa_rechazo) %>% 
  mutate(Comentarios = str_replace_all(Comentarios, "\n", " "),
         causa_rechazo = as.character(causa_rechazo)) %>% 
  unnest_tokens(word, Comentarios) %>%
  group_by(word) %>%
  filter(n() >= 5) %>%  
  ungroup()
```


```{r}
final_classifications <- tidy_final %>%
  inner_join(final_coefs, by = c("word" = "term")) %>%
  group_by(rowname, `Name/Id`, class) %>%
  summarize(score = sum(estimate)) %>%
  mutate(probability = plogis(score)) %>% 
  summarize(prob = max(probability), 
            response = class[which(probability == max(probability))]) %>% 
  ungroup()
```


```{r}
final_validation <- final_classifications %>%
  left_join(clean_verbatim %>%
    select(causa_rechazo, rowname, Comentarios, `Field of Expertise`, Ruta), by = "rowname") %>%
  mutate(response = fct_relevel((as_factor(response)), "técnico", "forma", "procedimiento")) %>% 
  select(-causa_rechazo)

write_excel_csv2(final_validation, "final_validation.csv")
```

## Need to join this data to the risk assessment database

```{r}
riesgo_planos <- fread("riesgo_planos_xjd.csv", encoding = "UTF-8") %>% as_tibble()
final_validation <- fread("final_validation.csv", encoding = "UTF-8") %>% as_tibble()
desarrollos_final <- fread("desarrollos_final.csv", encoding = "UTF-8") %>% as_tibble()


riesgo_planos_class <- riesgo_planos %>%
  mutate(perimetro = paste(ELTDEC_numero, "-", ELTDEC_designation)) %>% 
  left_join(final_validation %>% 
               select("DOCTECH_numero" = "Name/Id", "probabilidad" = prob, response, Comentarios, `Field of Expertise`, Ruta), by = "DOCTECH_numero") %>%
  select(perimetro, DOCTECH_numero, riesgo, Comentarios, response, probabilidad, ELTDEC_numero, Ruta,
         ELTDEC_designation, FCT_numero, FCT_designation, 
         ESO_num_PG, ESO_designation_PG, PIE_numero, 
         PIE_designation, PIEIND_Dernier_indice) %>% 
  group_by(DOCTECH_numero) %>%
  distinct(Comentarios, response, Ruta, .keep_all = T) %>% 
  ungroup()

riesgo_planos_class %>% 
  filter(FCT_numero %in% desarrollos_final$FCT_numero, !is.na(response)) %>% 
  write_xlsx("riesgo_planos_xjd_causas.xlsx")

desarrollos_final %>%
  semi_join(riesgo_planos, by = "FCT_numero") %>% 
  write_csv2("riesgo_funciones_xjd.csv")

```

La columna riesgo queda con 1 sólo valor de riesgo para cada referencia y ade

